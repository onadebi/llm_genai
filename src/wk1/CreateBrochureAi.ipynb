{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad509618-ce4e-4b5f-b100-613a203d68b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(override=True);\n",
    "\n",
    "api_key = os.getenv(\"OPEN_API_KEY\");\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPEN_API_KEY environment variable is not set.\")\n",
    "\n",
    "open_ai = OpenAI(api_key=api_key);\n",
    "MODEL = \"gpt-4o-mini\";\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MESSAGES = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Write a winning business idea to generate thousands of dollars online.\",\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "870d0237-24be-4051-b060-1b3381bc2d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class for fetching and processing website content.\n",
    "    \"\"\"\n",
    "    url: str;\n",
    "    title: str = None\n",
    "    content: str = None\n",
    "    summary: str = None\n",
    "    links: None\n",
    "\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url);\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser');\n",
    "            self.title = soup.title.string if soup.title else \"No title found\"\n",
    "            \n",
    "            # Remove irrelevant elements\n",
    "            for irrelevant in soup(['script', 'style', 'img', 'input', 'nav']):\n",
    "                irrelevant.decompose()\n",
    "            \n",
    "            self.content =soup.get_text(separator=\"\\n\", strip=False)\n",
    "            self.links = {a['href'] for a in soup.find_all('a', href=True)}\n",
    "        else:\n",
    "            print(f\"Failed to fetch {url}: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51e59041",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20a75388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt\n",
    "\n",
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = open_ai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "975e23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Home - Edward Donner"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===={'mailto:hello@mygroovydomain.com', 'https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html', 'https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/', 'https://edwarddonner.com/', 'https://nebula.io/?utm_source=ed&utm_medium=referral', 'https://www.linkedin.com/in/eddonner/', 'https://twitter.com/edwarddonner', 'https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/', 'https://patents.google.com/patent/US20210049536A1/', 'https://news.ycombinator.com', 'https://www.facebook.com/edward.donner.52', 'https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/', 'https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/'}====\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "short_read = Website(\"https://edwarddonner.com\");\n",
    "display(Markdown(f\"### {short_read.title}\"))\n",
    "\n",
    "print(f\"\\n\\n===={short_read.links}====\\n\\n\")\n",
    "\n",
    "# display(Markdown(short_read.content));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eefd37b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the list of links on the website of https://edwarddonner.com - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
      "Links (some might be relative links):\n",
      "mailto:hello@mygroovydomain.com\n",
      "https://www.prnewswire.com/news-releases/wynden-stark-group-acquires-nyc-venture-backed-tech-startup-untapt-301269512.html\n",
      "https://edwarddonner.com/2025/04/21/the-complete-agentic-ai-engineering-course/\n",
      "https://edwarddonner.com/\n",
      "https://nebula.io/?utm_source=ed&utm_medium=referral\n",
      "https://www.linkedin.com/in/eddonner/\n",
      "https://twitter.com/edwarddonner\n",
      "https://edwarddonner.com/2025/05/18/2025-ai-executive-briefing/\n",
      "https://patents.google.com/patent/US20210049536A1/\n",
      "https://news.ycombinator.com\n",
      "https://www.facebook.com/edward.donner.52\n",
      "https://edwarddonner.com/2025/01/23/llm-workshop-hands-on-with-agents-resources/\n",
      "https://edwarddonner.com/2025/05/28/connecting-my-courses-become-an-llm-expert-and-leader/\n"
     ]
    }
   ],
   "source": [
    "print(get_links_user_prompt(short_read));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c5bfb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'links': [{'type': 'about page', 'url': 'https://www.anthropic.com/'},\n",
       "  {'type': 'careers page', 'url': 'https://www.anthropic.com/jobs'},\n",
       "  {'type': 'learn page', 'url': 'https://www.anthropic.com/learn'},\n",
       "  {'type': 'news page', 'url': 'https://www.anthropic.com/news/claude-4'},\n",
       "  {'type': 'research page',\n",
       "   'url': 'https://www.anthropic.com/research/tracing-thoughts-language-model'}]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_links(\"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38650b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5f49ee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_prompt(website: str, system_prompt: str = None) -> tuple[list[dict[str, str]], int, str]:\n",
    "    \"\"\"\n",
    "    Forms a prompt for the LLM based on system and user inputs.\n",
    "    \"\"\"\n",
    "    if not system_prompt:\n",
    "        system_prompt = \"You are a helpful assistant that analyzes the content of a website and provides a short summary, ignoring texts that may be navigation related.\"\n",
    "\n",
    "    soup_props: BeautifulSoup = None\n",
    "    status_code: int = 403\n",
    "    error: str = None;\n",
    "    try:\n",
    "        response = requests.get(website)\n",
    "        status_code: int = response.status_code\n",
    "        if status_code == 200:\n",
    "            soup_props = BeautifulSoup(response.content, 'html.parser')\n",
    "            for irrelevant in soup_props(['script', 'style', 'img', 'input', 'nav']):\n",
    "                irrelevant.decompose()\n",
    "        else:\n",
    "            print(f\"Failed to fetch {website}: {status_code}\")\n",
    "            error = f\"Failed to fetch {website}: {status_code}\"\n",
    "            return ([], status_code, error)\n",
    "    except Exception as e:\n",
    "        # print(f\"An error occurred while fetching {website}: {e}\")\n",
    "        error = str(e)\n",
    "        return ([], status_code, error)\n",
    "    # if not soup_props:\n",
    "    #     raise ValueError(f\"Failed to fetch or parse the website: {website}\")\n",
    "\n",
    "    user_prompt = f\"You are looking at a website titled {soup_props.title.string if soup_props.title else 'No title found'}.\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += soup_props.get_text(separator=\"\\n\", strip=False)\n",
    "    prompts: list[dict[str, str]] = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_prompt\n",
    "        }\n",
    "    ]\n",
    "    return (prompts, status_code,error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c28347a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful assistant that analyzes the content of a website and provides a short summary, ignoring texts that may be navigation related.'}, {'role': 'user', 'content': 'You are looking at a website titled Onaefe Edebi.\\nThe contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOnaefe Edebi\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nüöß Under Construction üèóÔ∏è\\n\\n\\nIn the mean time, please check out my links below:\\n\\n\\n\\n\\n\\n\\n\\n            GitHub\\n        \\n\\n\\n\\n            LinkedIn\\n        \\n\\n\\n\\n            CourseRunway - AI Powered site to learn about any subject\\n        \\n\\n\\n\\n\\n\\n\\n\\n'}]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "======\n",
       "# Onaefe Edebi\n",
       "\n",
       "The website \"Onaefe Edebi\" is currently under construction. While the main content is not available, visitors are encouraged to explore links to external platforms such as GitHub, LinkedIn, and CourseRunway‚Äîan AI-powered site designed for learning about various subjects."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "the_prompt = from_prompt(\"https://onax.me\");\n",
    "print(the_prompt[0])\n",
    "\n",
    "# The 'temperature' parameter controls the randomness and creativity of the model's responses.\n",
    "# Lower values (e.g., 0.2) make the output more focused and deterministic.\n",
    "# # Higher values (e.g., 0.8) make the output more diverse and creative.\n",
    "if the_prompt[1] == 200:\n",
    "    response = open_ai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=the_prompt[0],\n",
    "        max_tokens=500,\n",
    "        temperature=0.7 # 0.7 is a moderate value, balancing creativity and coherence.\n",
    "    );\n",
    "    # print(f\"\\n\\n{response.choices[0].message.content}\")\n",
    "    display(Markdown(f\"\\n======\\n{response.choices[0].message.content}\"))\n",
    "else:\n",
    "    print(f\"Failed to generate response. Status Code: {the_prompt[1]} | Error: {the_prompt[2]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
